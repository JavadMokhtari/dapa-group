# Visualize Filters and Feature Maps in Convolutional Neural Networks
<p align=justify>In this study, we developed simple visualizations for filters and feature maps in a convolutional neural network. We utilized the DenseNet121 convolutional neural network to visualize the feature map. This model consists of blocks of convolutional layers, where each layer's input is connected to the output of all previous layers. The DenseNet architecture was introduced in 2017 and outperforms the ResNet model with fewer parameters. Both networks were designed to address the problem of vanishing gradient by incorporating residual connections.
We imported the pre-trained DenseNet121 model from the TensorFlow library and displayed the feature map for a bird input image after the concatenation layer, which is located after each block. The images showed that the initial layers of the model effectively extracted partial features and low-level patterns. However, as we moved towards the final layers of the model, it extracted higher-level features and gained a more comprehensive understanding of the input image. This observation is in line with the principles of deep learning and the hierarchical nature of convolutional neural networks.</p>

# Train Generative Adversarial Network (GAN)
<p align=justify>A Generative Adversarial Network (GAN) is a type of artificial intelligence (AI) that is used to generate new data by learning patterns in existing data. It consists of two neural networks: a generator and a discriminator. The generator is responsible for creating new data that is similar to the training data. It takes random noise as input and generates new samples of data. The discriminator, on the other hand, tries to distinguish between the real training data and the fake data generated by the generator. During training, the generator tries to generate data that is similar to the real data, while the discriminator tries to correctly identify which data is real and which is generated by the generator. This creates a feedback loop, where the generator learns to create better data by trying to fool the discriminator, and the discriminator learns to distinguish better between real and fake data.
Over time, the generator becomes better at creating data that is indistinguishable from real data, while the discriminator becomes better at distinguishing between real and fake data. This results in a generator that can create new data that is very similar to the training data, and can be used for tasks such as image or text generation. One key advantage of GANs is that they don't require labeled data, which is often expensive and time-consuming to create. Instead, they can learn to generate data based on unlabeled training data, making them a powerful tool for tasks such as image and text synthesis, and data augmentation.</p>

# Automated Number Plate Recognition using YOLO v7
<p align=justify>The objective of this project was to use the YOLO model to detect car number plates. The training was done with the following parameters: batch size of 16, 100 epochs on an image dataset that contains Iranian cars and non=Iranian cars. The weights used for the model were yolov7_training.pt that used as Transfer Learning approach. The YOLO model was effective in detecting car number plates with high accuracy. The results demonstrate the potential for using deep learning models in the field of automated number plate recognition (ANPR). Future work could involve exploring ways to improve the inference time and accuracy of the model.</p>
